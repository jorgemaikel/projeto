{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistema de Reconhecimento Facial com MTCNN, FaceNet e SVM\n",
    "\n",
    "Este notebook implementa um pipeline completo para reconhecimento facial, utilizando uma abordagem de três estágios:\n",
    "1.  **Detecção de Faces:** Usando a rede pré-treinada **MTCNN** para encontrar a localização das faces em uma imagem.\n",
    "2.  **Extração de Embeddings:** Usando a rede pré-treinada **FaceNet** para converter cada face em um vetor numérico de 128 dimensões que representa suas características únicas.\n",
    "3.  **Classificação:** Treinando um classificador **Support Vector Machine (SVM)** para associar os vetores de embedding aos nomes das pessoas.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-requisito: Preparar a Base de Dados no Google Drive\n",
    "\n",
    "Antes de executar o código, **recomendo fortemente** criar a seguinte estrutura de pastas e arquivos no seu Google Drive:\n",
    "\n",
    "```\n",
    "/content/drive/MyDrive/\n",
    "└── reconhecimento_facial/             # Pasta principal do projeto\n",
    "    ├── dataset/                     # Pasta com os dados para treinamento\n",
    "    │   ├── nome_pessoa_1/           # Subpasta para a primeira pessoa\n",
    "    │   │   ├── foto1.jpg\n",
    "    │   │   ├── foto2.png\n",
    "    │   │   └── ... (5 a 10 fotos da pessoa 1)\n",
    "    │   └── nome_pessoa_2/           # Subpasta para a segunda pessoa\n",
    "    │       ├── imagem_a.jpg\n",
    "    │       └── ... (5 a 10 fotos da pessoa 2)\n",
    "    └── imagem_teste.jpg             # Uma imagem de teste para a fase final\n",
    "```\n",
    "\n",
    "**Importante:** Os nomes das subpastas (`nome_pessoa_1`, etc.) serão usados como os rótulos para o reconhecimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase 1: Instalação das Bibliotecas e Montagem do Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala as dependências necessárias\n",
    "!pip install tensorflow keras opencv-python scikit-learn mtcnn keras-facenet\n",
    "\n",
    "# Monta o Google Drive para acessar os arquivos\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase 2: Funções Principais e Inicialização dos Modelos\n",
    "\n",
    "Nesta célula, importamos todas as bibliotecas, inicializamos os modelos pré-treinados (MTCNN para detecção e FaceNet para embeddings) e definimos a função principal que extrai a \"assinatura\" de uma face a partir de uma imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Importa os modelos e ferramentas\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras_facenet import FaceNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Inicializa os modelos pré-treinados (isso pode levar um momento)\n",
    "print(\"Carregando modelo de detecção MTCNN...\")\n",
    "detector = MTCNN()\n",
    "print(\"Carregando modelo de embedding FaceNet...\")\n",
    "embedder = FaceNet()\n",
    "print(\"Modelos carregados.\")\n",
    "\n",
    "def extrair_embedding(caminho_imagem):\n",
    "    \"\"\"\n",
    "    Detecta a face em uma imagem e extrai seu embedding (vetor de características).\n",
    "    \n",
    "    Args:\n",
    "        caminho_imagem (str): O caminho para o arquivo de imagem.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: O vetor de embedding da face (128 dimensões), ou None se nenhuma face for encontrada.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(caminho_imagem)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao abrir a imagem {caminho_imagem}: {e}\")\n",
    "        return None\n",
    "\n",
    "    img_rgb = img.convert('RGB')\n",
    "    pixels = np.asarray(img_rgb)\n",
    "    \n",
    "    resultados = detector.detect_faces(pixels)\n",
    "    \n",
    "    if resultados:\n",
    "        x1, y1, width, height = resultados[0]['box']\n",
    "        # Lida com coordenadas negativas, que podem ocorrer\n",
    "        x1, y1 = abs(x1), abs(y1)\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        \n",
    "        face_pixels = pixels[y1:y2, x1:x2]\n",
    "        face_img = Image.fromarray(face_pixels)\n",
    "        face_img = face_img.resize((160, 160))\n",
    "        face_array = np.asarray(face_img)\n",
    "        \n",
    "        face_array = face_array.astype('float32')\n",
    "        mean, std = face_array.mean(), face_array.std()\n",
    "        face_array = (face_array - mean) / std\n",
    "        face_array = np.expand_dims(face_array, axis=0)\n",
    "        \n",
    "        embedding = embedder.embeddings(face_array)\n",
    "        return embedding[0]\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase 3: Carregar Dataset e Treinar o Classificador SVM\n",
    "\n",
    "Agora, vamos processar todas as imagens do nosso dataset. Para cada imagem, extraímos o embedding da face e o associamos ao nome da pessoa (o nome da pasta). No final, treinamos um modelo SVM com esses dados e o salvamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATENÇÃO: Verifique se este caminho está correto!\n",
    "caminho_dataset = '/content/drive/MyDrive/reconhecimento_facial/dataset/'\n",
    "\n",
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "print(\"Iniciando processamento do dataset...\")\n",
    "for nome_pessoa in os.listdir(caminho_dataset):\n",
    "    caminho_pessoa = os.path.join(caminho_dataset, nome_pessoa)\n",
    "    \n",
    "    if os.path.isdir(caminho_pessoa):\n",
    "        for nome_imagem in os.listdir(caminho_pessoa):\n",
    "            caminho_imagem = os.path.join(caminho_pessoa, nome_imagem)\n",
    "            \n",
    "            embedding = extrair_embedding(caminho_imagem)\n",
    "            \n",
    "            if embedding is not None:\n",
    "                embeddings.append(embedding)\n",
    "                labels.append(nome_pessoa)\n",
    "                print(f\"Processado: {caminho_imagem}\")\n",
    "\n",
    "if embeddings:\n",
    "    embeddings = np.asarray(embeddings)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    # Normaliza os vetores de embedding\n",
    "    in_encoder = Normalizer(norm='l2')\n",
    "    embeddings = in_encoder.transform(embeddings)\n",
    "\n",
    "    # Codifica os rótulos para números\n",
    "    out_encoder = LabelEncoder()\n",
    "    out_encoder.fit(labels)\n",
    "    labels_encoded = out_encoder.transform(labels)\n",
    "\n",
    "    # Divide os dados para treino e teste (80% treino, 20% teste)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(embeddings, labels_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Treina o modelo SVM\n",
    "    modelo_svm = SVC(kernel='linear', probability=True)\n",
    "    modelo_svm.fit(X_train, y_train)\n",
    "\n",
    "    # Avalia o modelo\n",
    "    y_pred = modelo_svm.predict(X_test)\n",
    "    print(f\"\\nAcurácia do modelo nos dados de teste: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "\n",
    "    # Salva o modelo treinado e o codificador de rótulos\n",
    "    caminho_salvar = '/content/drive/MyDrive/reconhecimento_facial/'\n",
    "    with open(os.path.join(caminho_salvar, 'svm_classifier.pkl'), 'wb') as f:\n",
    "        pickle.dump(modelo_svm, f)\n",
    "    with open(os.path.join(caminho_salvar, 'label_encoder.pkl'), 'wb') as f:\n",
    "        pickle.dump(out_encoder, f)\n",
    "\n",
    "    print(f\"\\nModelo treinado e salvo com sucesso em: {caminho_salvar}\")\n",
    "else:\n",
    "    print(\"\\nNenhuma face foi processada. Verifique sua estrutura de pastas e as imagens.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase 4: Teste Final em uma Nova Imagem\n",
    "\n",
    "Esta célula final carrega os modelos que acabamos de salvar e executa o pipeline completo em uma imagem de teste. Ele irá detectar todas as faces, reconhecê-las e desenhar o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# --- Carregar modelos e dados salvos ---\n",
    "caminho_base = '/content/drive/MyDrive/reconhecimento_facial/'\n",
    "\n",
    "try:\n",
    "    with open(caminho_base + 'svm_classifier.pkl', 'rb') as f:\n",
    "        modelo_svm = pickle.load(f)\n",
    "    with open(caminho_base + 'label_encoder.pkl', 'rb') as f:\n",
    "        out_encoder = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"Erro: Arquivos de modelo não encontrados. Certifique-se de que a Fase 3 foi executada com sucesso.\")\n",
    "\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "\n",
    "# --- Carregar imagem de teste ---\n",
    "# ATENÇÃO: Altere o nome do arquivo para a sua imagem de teste!\n",
    "caminho_imagem_teste = '/content/drive/MyDrive/reconhecimento_facial/imagem_teste.jpg'\n",
    "\n",
    "try:\n",
    "    img_teste = cv2.imread(caminho_imagem_teste)\n",
    "    img_rgb = cv2.cvtColor(img_teste, cv2.COLOR_BGR2RGB)\n",
    "    pixels = np.asarray(img_rgb)\n",
    "\n",
    "    # Detectar todas as faces na imagem\n",
    "    faces = detector.detect_faces(pixels)\n",
    "\n",
    "    if faces:\n",
    "        print(f\"{len(faces)} face(s) detectada(s).\")\n",
    "        for face_info in faces:\n",
    "            x1, y1, width, height = face_info['box']\n",
    "            x1, y1 = abs(x1), abs(y1)\n",
    "            x2, y2 = x1 + width, y1 + height\n",
    "            \n",
    "            face_pixels = pixels[y1:y2, x1:x2]\n",
    "            face_img = Image.fromarray(face_pixels).resize((160, 160))\n",
    "            face_array = np.asarray(face_img).astype('float32')\n",
    "            \n",
    "            mean, std = face_array.mean(), face_array.std()\n",
    "            face_array = (face_array - mean) / std\n",
    "            face_array = np.expand_dims(face_array, axis=0)\n",
    "            \n",
    "            embedding = embedder.embeddings(face_array)\n",
    "            embedding_norm = in_encoder.transform(embedding)\n",
    "            \n",
    "            # Fazer a predição\n",
    "            predicao_numerica = modelo_svm.predict(embedding_norm)\n",
    "            probabilidade = modelo_svm.predict_proba(embedding_norm)\n",
    "            confianca = np.max(probabilidade)\n",
    "            \n",
    "            nome_predito = out_encoder.inverse_transform(predicao_numerica)[0]\n",
    "            \n",
    "            # Se a confiança for baixa, classificar como \"Desconhecido\"\n",
    "            if confianca < 0.85:\n",
    "                nome_predito = \"Desconhecido\"\n",
    "                cor_retangulo = (0, 0, 255) # Vermelho para desconhecido\n",
    "            else:\n",
    "                cor_retangulo = (0, 255, 0) # Verde para conhecido\n",
    "            \n",
    "            # Desenhar retângulo e texto na imagem original\n",
    "            cv2.rectangle(img_teste, (x1, y1), (x2, y2), cor_retangulo, 2)\n",
    "            texto = f'{nome_predito} ({confianca*100:.2f}%)'\n",
    "            cv2.putText(img_teste, texto, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, cor_retangulo, 2)\n",
    "\n",
    "        # Exibir o resultado\n",
    "        print(\"\\nExibindo resultado...\")\n",
    "        cv2_imshow(img_teste)\n",
    "    else:\n",
    "        print(\"Nenhuma face foi detectada na imagem de teste.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: Imagem de teste não encontrada em '{caminho_imagem_teste}'. Verifique o caminho e o nome do arquivo.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro inesperado: {e}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
